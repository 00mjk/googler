#!/usr/bin/env python
#
# Copyright (C) 2008 Henri Hakkinen
#
# Modified (2015) by Arun Prakash Jana <engineerarun@gmail.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from __future__ import print_function
import argparse
import fcntl
import gzip
import io
import os
import readline
import struct
import sys
import tempfile
import textwrap
import termios
import webbrowser

# 2to3 compatibility layer
if sys.version_info > (3,):
    from html.entities import name2codepoint
    import html.parser as HTMLParser
    from urllib.parse import (
        urljoin,
        quote_plus as url_quote_plus,
        unquote as url_unquote,
    )
    from urllib.parse import unquote as url_unquote
    from http.client import HTTPSConnection

    unichr = chr
    raw_input = input
else:
    from htmlentitydefs import name2codepoint
    import HTMLParser
    from urllib import (
        quote_plus as url_quote_plus,
        unquote as url_unquote,
    )
    from urlparse import urljoin
    from httplib import HTTPSConnection


# Global variables

columns = None    # Terminal window size.
start = "0"       # The first result to display (option -s)
num = None        # Number of results to display (option -n)
lang = None       # Language to search for (option -l)
openUrl = False   # If True, opens the first URL in browser (option -j)
colorize = True   # If True, colorizes the output (option -C)
duration = None   # Time limit search (option -t) [e.g. h5, d5, w5, m5, y5]
conn = None       # Use a single global connection during navigation
nav = "n"         # For user navigation
skipped = 0       # Count for skipped ads or blank links
debug = False     # Print debug logs
news = False      # Read news
exact = False     # If True, disable automatic spelling correction
server = "www.google.com"
ua = ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
      '(KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.10240')
                  # Disguise as Microsoft Edge


# Classes

class GoogleParser(HTMLParser.HTMLParser):

    def __init__(self):
        HTMLParser.HTMLParser.__init__(self)
        self.handle_starttag = self.main_start
        self.handle_data = self.main_data
        self.handle_endtag = self.main_end
        # Use stacks to keep track of the hirarchy of entityref/charref handlers
        self.old_entityref_handlers = [self.handle_entityref]
        self.old_charref_handlers = [self.handle_charref]
        self.results = []

    def main_start(self, tag, attrs):
        if tag == "div" and len(attrs) > 0 and attrs[0] == ("class", "g"):
            self.title = ""
            self.url = ""
            self.text = ""
            self.handle_starttag = self.div_outer_start
            self.handle_data = self.div_outer_data
            self.handle_endtag = self.div_outer_end

    def main_data(self, data):
        pass

    def main_end(self, tag):
        pass

    # outer <div class="g"> ... </div>
    def div_outer_start(self, tag, attrs):
        if tag == "h3":
            self.handle_starttag = self.h3_start
            self.handle_data = self.h3_data
            self.register_entityref_and_charref_handlers('title')
            self.handle_endtag = self.h3_end
        elif tag == "div" and len(attrs) > 0 and attrs[0] == ("class", "s"):
            self.handle_starttag = self.div_inner_start
            self.handle_data = self.div_inner_data
            self.handle_endtag = self.div_inner_end

    def div_outer_data(self, data):
        pass

    def div_outer_end(self, tag):
        global skipped

        if tag == "div":
            marker = self.url.find("?q=")
            if marker >= 0:
                self.url = self.url[marker + 3:]
            marker = self.url.find("&sa")
            if marker >= 0:
                self.url = self.url[:marker]

            if self.url != "":
                if self.url.find("://", 0, 12) >= 0:
                    index = len(self.results) + 1
                    self.results.append(Result(index, self.title,
                                               url_unquote(self.url),
                                               self.text))
                else:
                    skipped += 1

            self.handle_starttag = self.main_start
            self.handle_data = self.main_data
            self.handle_endtag = self.main_end

    # <h3> ... </h3>
    def h3_start(self, tag, attrs):
        if tag == "a":
            for name, value in attrs:
                if name == "href":
                    self.url = value

    def h3_data(self, data):
        self.title += data

    def h3_end(self, tag):
        if tag == "h3":
            self.handle_starttag = self.div_outer_start
            self.handle_data = self.div_outer_data
            self.restore_entityref_and_charref_handlers()
            self.handle_endtag = self.div_outer_end

    # inner <div> ... </div>
    def div_inner_start(self, tag, attrs):
        if tag == "span" and len(attrs) > 0 and attrs[0] == ("class", "st"):
            self.handle_starttag = self.span_outer_start
            self.handle_data = self.span_outer_data
            self.register_entityref_and_charref_handlers('text')
            self.handle_endtag = self.span_outer_end

    def div_inner_data(self, data):
        pass

    def div_inner_end(self, tag):
        pass

    def span_outer_start(self, tag, attrs):
        if tag == "span" and len(attrs) > 0 and attrs[0] == ("class", "f"):
            self.handle_starttag = self.span_inner_start
            self.handle_data = self.span_inner_data
            self.register_entityref_and_charref_handlers('text')
            self.handle_endtag = self.span_inner_end

    def span_outer_data(self, data):
        self.text += data

    def span_outer_end(self, tag):
        if tag == "span":
            self.handle_starttag = self.div_outer_start
            self.handle_data = self.div_outer_data
            self.restore_entityref_and_charref_handlers()
            self.handle_endtag = self.div_outer_end

    def span_inner_start(self, tag, start):
        pass

    def span_inner_data(self, data):
        self.text += data

    def span_inner_end(self, tag):
        if tag == "span":
            self.handle_starttag = self.span_outer_start
            self.handle_data = self.span_outer_data
            self.restore_entityref_and_charref_handlers()
            self.handle_endtag = self.span_outer_end

    # Register entityref and charref handlers so that decoded refs are
    # appended to the attribute (of self) named dest (e.g., 'title' or
    # 'text').
    def register_entityref_and_charref_handlers(self, dest):
        self.old_entityref_handlers.append(self.handle_entityref)
        self.old_charref_handlers.append(self.handle_charref)
        self.handle_entityref = lambda ref: self.entityref(dest, ref)
        self.handle_charref = lambda ref: self.charref(dest, ref)

    def restore_entityref_and_charref_handlers(self):
        self.handle_entityref = self.old_entityref_handlers.pop()
        self.handle_charref = self.old_charref_handlers.pop()

    def entityref(self, dest, ref):
        try:
            char = unichr(name2codepoint[ref])
            setattr(self, dest, getattr(self, dest) + char)
        except KeyError:
            # Entity name not found; most likely rather sloppy HTML
            # where a literal ampersand is not escaped; For instance,
            # the HTML response returned by
            #
            #     googler -c au -l ko expected
            #
            # contains the following tag
            #
            #     <p class="_e4b"><a href="...">expected market return s&p 500</a></p>
            #
            # where &p is interpreted by HTMLParser as an entity (this
            # behavior seems to be specific to Python 2.7).
            setattr(self, dest, getattr(self, dest) + '&' + ref)

    def charref(self, dest, ref):
        if ref.startswith('x'):
            char = unichr(int(ref[1:], 16))
        else:
            char = unichr(int(ref))
        setattr(self, dest, getattr(self, dest) + char)


class Result:

    def __init__(self, index, title, url, text):
        self.index = index
        self.title = title
        self.url = url
        self.text = text

    def print_entry(self):
        index = self.index
        title = self.title
        url = self.url
        text = self.text

        # Open the URL in a web browser if option -j was specified.
        if openUrl:
            self.open()
            quit(conn)

        # Print the title and the URL.
        if colorize:
            print("\x1B[1m\x1B[36m", index, "\x1B[92m", title,
                  "\x1B[0m\n\x1B[93m%s\x1B[39m" % url)
        else:
            print("", index, title, "\n%s" % url)
        # Hard wrap text if the number of columns is available.
        if columns > 0:
            col = 0
            for w in text.split():
                if (col + len(w) + 1) > columns:
                    col = 0
                    print()
                print(w, end=' ')
                col += len(w) + 1
            print("\n")
        else:
            print("%s\n" % text.replace("\n", " "))

    def open(self):
        _stderr = os.dup(2)
        os.close(2)
        _stdout = os.dup(1)
        os.close(1)
        fd = os.open(os.devnull, os.O_RDWR)
        os.dup2(fd, 2)
        os.dup2(fd, 1)
        try:
            webbrowser.open(self.url)
        finally:
            os.close(fd)
            os.dup2(_stderr, 2)
            os.dup2(_stdout, 1)


# Functions

def is_int(string):
    try:
        int(string)
        return True
    except:
        return False

def serverURL(domain):
    # Google domain ref: https://en.wikipedia.org/wiki/List_of_Google_domains
    # www.google.co.domain
    if domain in ["id", "in", "jp", "kr", "uk"]:
        return "www.google.co." + domain
    if domain in ["be", "ca", "ch", "cz", "de", "es", "fi", "fr", "it", "nl",
                  "pl", "pt", "ro", "ru", "se"]:    # www.google.domain
        return "www.google." + domain
    # www.google.com.domain
    if domain in ["ar", "au", "br", "mx", "ph", "tw", "ua"]:
        return "www.google.com." + domain

    return "www.google.com"


# Send a GET request to Google with the appropriate headers.
# url can be relative (to the appropriate Google domain).
def google_get(conn, url):
    global ua
    conn.request("GET", url, None, {
        "Accept-encoding": "gzip",
        "User-Agent": ua,
    })
    return conn.getresponse()


# Returns a new connection to the given domain with appropriate options.
# When the given domain is absent, the global variable server is used
# instead.
def new_connection(domain=None):
    global server
    return HTTPSConnection(domain if domain else server, timeout=45)


# Closes a connection and quits the program
def quit(conn):
    conn.close()
    sys.exit(1)


# Show the search or navigation omniprompt:
def show_omniprompt():
    global colorize

    message = "Enter n, p, result number or new keywords"
    if colorize:
        return raw_input("\x1b[7m%s\x1b[0m " % message)
    else:
        return raw_input("%s: " % message)


# Program Main

# Process command line options.
optlist = None
keywords = None

class ExtendedArgumentParser(argparse.ArgumentParser):

    # Augment print_help to print more than synopsis and options
    def print_help(self, file=None):
        super(ExtendedArgumentParser, self).print_help(file)
        file.write(textwrap.dedent("""
        prompt keys:
          g terms  initiate a new search for 'terms' with original options
          n, p     fetch next or previous set of search results
          1-N      open the Nth result index in browser
          Enter    exit googler (same behaviour for an empty search)
          *        any other string initiates a new search with original options

        Version 2.2
        Copyright (C) 2008 Henri Hakkinen.
        Modified (2015) by Arun Prakash Jana <engineerarun@gmail.com>
        Webpage: https://github.com/jarun/googler
        """))

    # Automatically print full help text on error
    def error(self, message):
        sys.stderr.write('%s: error: %s\n\n' % (self.prog, message))
        self.print_help(sys.stderr)
        self.exit(2)

def is_duration(arg):
    """Check if a string is a valid duration accepted by Google.

    A valid duration is of the form dNUM, where d is a single letter h
    (hour), d (day), w (week), m (month), or y (year), and NUM is a
    nonnegative integer.
    """
    try:
        if arg[0] not in ('h', 'd', 'w', 'm', 'y') or int(arg[1:]) < 0:
            raise ValueError
    except (TypeError, IndexError, ValueError):
        raise argparse.ArgumentTypeError('%s is not a valid duration' % arg)
    return arg

argparser = ExtendedArgumentParser(
    add_help=False,
    description='Performs a Google search and prints the results to stdout.'
)
addarg = argparser.add_argument
addarg('-s', dest='start', type=int, metavar='N',
       help='start at the Nth result')
addarg('-n', dest='num', type=int, metavar='N',
       help='show N results (default 10)')
addarg('-N', dest='news', action='store_true',
       help='show results from news section')
addarg('-c', dest='country', metavar='SERV',
       help='country-specific search (refer man or project page for details)')
addarg('-l', dest='lang', metavar='LANG',
       help='display in language LANG')
addarg('-x', dest='exact', action='store_true',
       help='disable automatic spelling correction')
addarg('-C', dest='colorize', action='store_false',
       help='disable color output')
addarg('-j', dest='openUrl', action='store_true',
       help='open the first result in a web browser')
addarg('-t', dest='duration', type=is_duration, metavar='dN',
       help='time limit search '
       '[h5 (5 hrs), d5 (5 days), w5 (5 weeks), m5 (5 months), y5 (5 years)]')
addarg('-d', dest='debug', action='store_true',
       help='enable debugging')
addarg('keywords', nargs='+', metavar='KEYWORD',
       help='search keywords')

if len(sys.argv) < 2:
    argparser.print_help(sys.stderr)
    sys.exit(1)

args = argparser.parse_args()
if args.start:
    start = str(args.start)
if args.num:
    num = str(args.num)
news = args.news
if args.country:
    server = serverURL(args.country)
lang = args.lang
exact = args.exact
colorize = args.colorize
openUrl = args.openUrl
duration = args.duration
debug = args.debug
keywords = args.keywords


# Construct the query URL.
url = "/search?ie=UTF-8&oe=UTF-8&"

if start is not None:
    url += "start=" + start + "&"
if num is not None:
    url += "num=" + num + "&"
if news:
    url += "tbm=nws&"
if lang is not None:
    url += "hl=" + lang + "&"
if duration is not None:
    url += "tbs=qdr:" + duration + "&"
if exact:
    url += "nfpr=1&"

baseurl = url
basestart = start

if debug:
    print("[DEBUG] Base URL [%s]" % url)

url += "q=" + url_quote_plus(keywords[0])
for kw in keywords[1:]:
    url += "+" + url_quote_plus(kw)

if debug:
    print("[DEBUG] Search URL [%s : %s]" % (server, url))

# Get the terminal window size.
try:
    winsz = fcntl.ioctl(sys.stderr, termios.TIOCGWINSZ, "1234")
    columns = struct.unpack("HH", winsz)[1]

    if columns <= 0:
        columns = int(os.environ.get('COLUMNS', 0))
except IOError:
    columns = 0

# Connect to Google and request the result page.
conn = new_connection()


def fetch_results():
    global conn
    global url
    global skipped

    try:
        resp = google_get(conn, url)
    except Exception as e:
        if debug:
            print("[DEBUG] Exception: %s" % e)
        conn.close()
        conn = new_connection()
        resp = google_get(conn, url)

    if resp.status != 200:
        if resp.status in (301, 302,):
            url = urljoin(url, resp.getheader('location', ''))
            if debug:
                print("[DEBUG] Redirected URL [%s]" % url)
            if url.find("sorry/IndexRedirect?") >= 0:
                print("ERROR: Connection blocked due to unusual activity.")
                quit(conn)

            conn.close()
            if debug:
                print("[DEBUG] Next Server [%s]" % url[url.find("//") +
                                                       2:url.find("/search")])
            conn = new_connection(url[url.find("//") + 2:url.find("/search")])
            url = url[url.find("/search"):]
            if debug:
                print("[DEBUG] Next GET [%s]" % url)

            try:
                resp = google_get(conn, url)
            except Exception as e:
                print("[DEBUG] Exception: %s" % e)
                quit(conn)

            if resp.status != 200:
                # Failed connecting to redirected server too!
                print("ERROR after 1st redirection:", str(resp.status), ": ",
                      resp.reason)
                quit(conn)
        else:
            # The server responded with an error.
            print("ERROR:", str(resp.status), ": ", resp.reason)
            quit(conn)

    # Parse the HTML document and print the results.
    parser = GoogleParser()
    resp_body = gzip.GzipFile(fileobj=io.BytesIO(resp.read())).read().decode('utf-8')

    if debug:
        fd, tmpfile = tempfile.mkstemp(prefix='googler-response-')
        os.close(fd)
        with open(tmpfile, 'wb') as fp:
            fp.write(resp_body.encode('utf-8'))
        print("[DEBUG] Response body written to '%s'.\n" % tmpfile)

    parser.feed(resp_body)

    results = parser.results
    for r in results:
        r.print_entry()

    if skipped:
        if skipped == 1:
            print("%d ad skipped." % skipped)
        else:
            print("%d ads skipped." % skipped)

        skipped = 0

    return results


results = []
while True:
    if nav == "n" or nav == "p" or nav == "g":
        results = fetch_results()

    oldstart = start
    try:
        nav = show_omniprompt()
    except EOFError:
        nav = ""

    if nav == "n":
        if num is not None:
            start = str(int(start) + int(num))
        else:
            start = str(int(start) + 10)
        print("")
    elif nav == "p":
        if num is not None:
            start = str(int(start) - int(num))
        else:
            start = str(int(start) - 10)
        print("")
    elif len(nav) > 2 and nav[0] == "g" and nav[1] == " ":
        trimsearch = nav[2:].strip().replace(" ", "+")
        if trimsearch == "":
            print("Empty search. Exiting.")
            break
        url = baseurl + "q=" + trimsearch
        if debug:
            print("New search URL [%s]" % url)
        nav = "g"
        start = basestart
        print("")
        continue
    elif is_int(nav):
        index = int(nav) - 1
        if index < 0:
            if index < -1:
                print("Index out of bound.")
            else:
                print("Index out of bound. To search %s, try \'g %s\'." % (nav, nav))
            continue

        try:
            results[index].open()
        except IndexError:
            print("Index out of bound. To search %s, try \'g %s\'." % (nav, nav))

        continue
    elif len(nav):
        trimsearch = nav.strip().replace(" ", "+")
        if trimsearch == "":
            print("Empty search. Exiting.")
            break
        url = baseurl + "q=" + trimsearch
        if debug:
            print("New search URL [%s]" % url)
        nav = "g"
        start = basestart
        print("")
        continue
    else:
        break

    if int(start) < 0:
        start = "0"

    url = url.replace("start=" + oldstart + "&", "start=" + start + "&", 1)
    if debug:
        print("[DEBUG] Next URL [%s]\n" % url)

conn.close()
